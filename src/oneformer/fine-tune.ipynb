{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\n",
    "\n",
    "# Replace the head of the pre-trained model\n",
    "processor = OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_ade20k_swin_tiny\")\n",
    "model = OneFormerForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_ade20k_swin_tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference \n",
    "\n",
    "def panoptic_run(img, predictor, metadata):\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, instance_mode=ColorMode.IMAGE)\n",
    "    predictions = predictor(img, \"panoptic\")\n",
    "    panoptic_seg, segments_info = predictions[\"panoptic_seg\"]\n",
    "    out = visualizer.draw_panoptic_seg_predictions(\n",
    "    panoptic_seg.to(cpu_device), segments_info, alpha=0.5\n",
    "    )\n",
    "    return out\n",
    "\n",
    "%load_ext autotime\n",
    "out = panoptic_run(img, predictor, metadata).get_image()\n",
    "cv2_imshow(out[:, :, ::-1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
